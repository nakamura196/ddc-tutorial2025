{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nakamura196/ddc-tutorial2025/blob/main/notebooks/tutorial_01_rawgraphs/convert_for_rawgraphs.ipynb)\n\n# NDL SRU検索結果をRAWGraphs用に変換\n\nNDL（国立国会図書館）SRU検索結果CSVをRAWGraphsで可視化するためのデータに変換します。\n\n## 入出力\n\n- **入力**: `ndl_sru_grouped_result.csv`\n- **出力**: `ndl_sru_for_rawgraphs.csv`\n- **NDCラベル**: `ndc9_class91_hierarchical.csv`（`fetch_ndc_labels.ipynb`で取得）\n\n## 出力フィールド\n\n| フィールド | 説明 |\n|-----------|------|\n| year | 出版年（1800-1867） |\n| title | 作品名 |\n| ndc_code | NDCコード（番号のみ） |\n| genre | NDCコード:ジャンル名（階層ラベル） |\n| genre_major | 大分類のみ（詩歌、小説等） |\n| location | 出版地（正規化済み） |\n| creator_normalized | 上位著者（その他/不明） |"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 年の範囲\n",
    "MIN_YEAR = 1800\n",
    "MAX_YEAR = 1867\n",
    "\n",
    "# 上位著者の数（これ以外は「その他」に集約）\n",
    "TOP_N_CREATORS = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ライブラリのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from collections import Counter\n",
    "from io import StringIO\n",
    "\n",
    "import pandas as pd  # Google Colabにはプリインストール済み"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## データファイルの準備\n\nGoogle Colabの場合、GitHubからデータをダウンロードします。\nローカル環境の場合は、カレントディレクトリのファイルを使用します。"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# データファイルの準備\nimport urllib.request\n\n# Google Colabかどうかを判定\ntry:\n    import google.colab\n    IS_COLAB = True\nexcept ImportError:\n    IS_COLAB = False\n\nif IS_COLAB:\n    # Google Colab: GitHubからデータをダウンロード\n    BASE_URL = \"https://raw.githubusercontent.com/nakamura196/ddc-tutorial2025/refs/heads/main\"\n    \n    # NDCラベルファイルをダウンロード\n    ndc_url = f\"{BASE_URL}/notebooks/tutorial_01_rawgraphs/ndc9_class91_hierarchical.csv\"\n    urllib.request.urlretrieve(ndc_url, \"ndc9_class91_hierarchical.csv\")\n    print(f\"ダウンロード完了: ndc9_class91_hierarchical.csv\")\n    \n    # 入力データファイルをダウンロード\n    data_url = f\"{BASE_URL}/data/ndl_sru_grouped_result.csv\"\n    urllib.request.urlretrieve(data_url, \"ndl_sru_grouped_result.csv\")\n    print(f\"ダウンロード完了: ndl_sru_grouped_result.csv\")\n    \n    INPUT_FILE = \"ndl_sru_grouped_result.csv\"\nelse:\n    # ローカル環境: 相対パスを使用\n    print(\"ローカル環境で実行中。相対パスのファイルを使用します。\")\n    INPUT_FILE = \"../../data/ndl_sru_grouped_result.csv\""
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ヘルパー関数の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ndc_labels(csv_path: str) -> dict:\n",
    "    \"\"\"\n",
    "    NDCラベルCSVを読み込んで辞書を返す\n",
    "\n",
    "    Args:\n",
    "        csv_path: ndc9_class91_hierarchical.csv のパス\n",
    "\n",
    "    Returns:\n",
    "        {NDCコード: 階層ラベル} の辞書\n",
    "    \"\"\"\n",
    "    labels = {}\n",
    "    try:\n",
    "        with open(csv_path, 'r', encoding='utf-8') as f:\n",
    "            reader = csv.DictReader(f)\n",
    "            for row in reader:\n",
    "                code = row['code']\n",
    "                labels[code] = row['label_hierarchical']\n",
    "    except FileNotFoundError:\n",
    "        print(f\"警告: {csv_path} が見つかりません。fetch_ndc_labels.ipynb を実行してください。\")\n",
    "\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndc_to_genre(ndc: str, ndc_labels: dict) -> tuple:\n",
    "    \"\"\"\n",
    "    単一のNDCコードからジャンル情報を返す\n",
    "\n",
    "    Returns:\n",
    "        (ndc_code, genre, genre_major) のタプル\n",
    "        - ndc_code: NDCコード（番号のみ）\n",
    "        - genre: NDCコード:階層ラベル\n",
    "        - genre_major: 大分類のみ\n",
    "    \"\"\"\n",
    "    if not ndc:\n",
    "        return (\"\", \"不明\", \"不明\")\n",
    "\n",
    "    ndc = ndc.strip()\n",
    "    matched_code = \"\"\n",
    "    matched_label = \"\"\n",
    "\n",
    "    # 完全一致を優先して検索\n",
    "    if ndc in ndc_labels:\n",
    "        matched_code = ndc\n",
    "        matched_label = ndc_labels[ndc]\n",
    "    else:\n",
    "        # 前方一致で検索（より具体的なコードを先にチェック）\n",
    "        for code in sorted(ndc_labels.keys(), key=len, reverse=True):\n",
    "            if ndc.startswith(code):\n",
    "                matched_code = code\n",
    "                matched_label = ndc_labels[code]\n",
    "                break\n",
    "\n",
    "    if not matched_code:\n",
    "        return (ndc, \"その他\", \"その他\")\n",
    "\n",
    "    # 大分類を抽出（階層ラベルの最初の部分）\n",
    "    genre_major = matched_label.split('/')[0] if matched_label else \"その他\"\n",
    "\n",
    "    return (matched_code, f\"{matched_code}:{matched_label}\", genre_major)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_location(loc: str) -> str:\n",
    "    \"\"\"単一の出版地を正規化する\"\"\"\n",
    "    if not loc:\n",
    "        return \"不明\"\n",
    "\n",
    "    loc = loc.strip()\n",
    "\n",
    "    # 江戸系\n",
    "    if any(x in loc for x in ['江戸', '東都', '東京']):\n",
    "        return \"江戸\"\n",
    "    # 京都系\n",
    "    elif any(x in loc for x in ['京都', '皇都', '平安', '京']):\n",
    "        return \"京都\"\n",
    "    # 大阪系\n",
    "    elif any(x in loc for x in ['大阪', '大坂', '浪華', '浪花', '坂陽']):\n",
    "        return \"大阪\"\n",
    "    elif '名古屋' in loc:\n",
    "        return \"名古屋\"\n",
    "    elif '長崎' in loc:\n",
    "        return \"長崎\"\n",
    "    elif '金沢' in loc:\n",
    "        return \"金沢\"\n",
    "    elif '出版地不明' in loc:\n",
    "        return \"不明\"\n",
    "    elif loc:\n",
    "        return \"その他\"\n",
    "    else:\n",
    "        return \"不明\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_multi_value(value: str, separator: str = ';') -> list:\n",
    "    \"\"\"セミコロン区切りの複数値を分割してリストで返す\"\"\"\n",
    "    if not value:\n",
    "        return ['']\n",
    "    return [v.strip() for v in value.split(separator)]\n",
    "\n",
    "\n",
    "def get_first_value(value: str, separator: str = ';') -> str:\n",
    "    \"\"\"セミコロン区切りの複数値から最初の値のみを取得\"\"\"\n",
    "    if not value:\n",
    "        return ''\n",
    "    return value.split(separator)[0].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_year(issued: str, min_year: int = MIN_YEAR, max_year: int = MAX_YEAR) -> int:\n",
    "    \"\"\"issued文字列から年を抽出する（範囲外はNone）\"\"\"\n",
    "    if not issued:\n",
    "        return None\n",
    "\n",
    "    year_str = issued[:4]\n",
    "    try:\n",
    "        year = int(year_str)\n",
    "        if min_year <= year <= max_year:\n",
    "            return year\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_creator_name(creator: str) -> str:\n",
    "    \"\"\"単一の著者名から名前部分のみを抽出（生没年を除去）\"\"\"\n",
    "    if not creator:\n",
    "        return \"\"\n",
    "    creator = creator.strip()\n",
    "    parts = creator.split(',')\n",
    "    if len(parts) >= 2:\n",
    "        return f\"{parts[0].strip()} {parts[1].strip()}\"\n",
    "    else:\n",
    "        return creator.split('∥')[0].strip()\n",
    "\n",
    "\n",
    "def get_top_creators(rows: list, top_n: int = TOP_N_CREATORS) -> set:\n",
    "    \"\"\"上位N名の著者名セットを返す（複数著者も全てカウント）\"\"\"\n",
    "    creator_count = Counter()\n",
    "\n",
    "    for row in rows:\n",
    "        creators_raw = row.get('creators_name', '')\n",
    "        if creators_raw:\n",
    "            for creator in split_multi_value(creators_raw):\n",
    "                name = parse_creator_name(creator)\n",
    "                if name:\n",
    "                    creator_count[name] += 1\n",
    "\n",
    "    return set(name for name, _ in creator_count.most_common(top_n))\n",
    "\n",
    "\n",
    "def normalize_creator(creator: str, top_creators: set) -> str:\n",
    "    \"\"\"単一の著者名を正規化（上位著者以外は「その他」）\"\"\"\n",
    "    if not creator:\n",
    "        return \"不明\"\n",
    "\n",
    "    name = parse_creator_name(creator)\n",
    "    if not name:\n",
    "        return \"不明\"\n",
    "\n",
    "    if name in top_creators:\n",
    "        return name\n",
    "    else:\n",
    "        return \"その他\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCラベル: 216件\n"
     ]
    }
   ],
   "source": [
    "# NDCラベルを読み込み\n",
    "ndc_labels = load_ndc_labels('ndc9_class91_hierarchical.csv')\n",
    "print(f\"NDCラベル: {len(ndc_labels)}件\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 入力ファイル読み込み\nwith open(INPUT_FILE, 'r', encoding='utf-8-sig') as f:\n    reader = csv.DictReader(f)\n    rows = list(reader)\n\nprint(f\"入力: {len(rows)}件\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 上位著者を抽出\n",
    "top_creators = get_top_creators(rows, TOP_N_CREATORS)\n",
    "print(f\"\\n上位{TOP_N_CREATORS}著者:\")\n",
    "for c in sorted(top_creators):\n",
    "    print(f\"  - {c}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データ変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 変換処理（複数値は最初の値のみ使用）\n",
    "output_rows = []\n",
    "skipped_count = 0\n",
    "\n",
    "for row in rows:\n",
    "    # 各フィールドの最初の値を取得\n",
    "    year = extract_year(get_first_value(row.get('issued', '')))\n",
    "    if year is None:\n",
    "        skipped_count += 1\n",
    "        continue  # 年が取得できない行はスキップ\n",
    "\n",
    "    # NDC情報を取得（コード、階層ラベル、大分類）\n",
    "    ndc_code, genre, genre_major = ndc_to_genre(\n",
    "        get_first_value(row.get('ndc_raw', '')), ndc_labels\n",
    "    )\n",
    "\n",
    "    output_rows.append({\n",
    "        'year': year,\n",
    "        'title': get_first_value(row.get('title_main', '')),\n",
    "        'ndc_code': ndc_code,\n",
    "        'genre': genre,\n",
    "        'genre_major': genre_major,\n",
    "        'location': normalize_location(get_first_value(row.get('publisher_location', ''))),\n",
    "        'creator_normalized': normalize_creator(get_first_value(row.get('creators_name', '')), top_creators)\n",
    "    })\n",
    "\n",
    "print(f\"変換完了: {len(output_rows)}件（年不明{skipped_count}件除外）\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrameに変換\n",
    "df = pd.DataFrame(output_rows)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 統計情報の表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== ジャンル大分類 ===\")\n",
    "genre_major_count = df['genre_major'].value_counts()\n",
    "for g, c in genre_major_count.items():\n",
    "    print(f\"  {c:4d}: {g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== ジャンル詳細分布 ===\")\n",
    "genre_count = df['genre'].value_counts()\n",
    "for g, c in genre_count.items():\n",
    "    print(f\"  {c:4d}: {g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== 出版地分布 ===\")\n",
    "loc_count = df['location'].value_counts()\n",
    "for l, c in loc_count.items():\n",
    "    print(f\"  {c:4d}: {l}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== 著者分布 ===\")\n",
    "creator_count = df['creator_normalized'].value_counts()\n",
    "for cr, c in creator_count.items():\n",
    "    print(f\"  {c:4d}: {cr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSVファイルとしてダウンロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全データを保存\n",
    "output_filename = 'ndl_sru_for_rawgraphs.csv'\n",
    "df.to_csv(output_filename, index=False, encoding='utf-8')\n",
    "print(f\"保存: {output_filename}（{len(df)}件）\")\n",
    "\n",
    "# 1800年除外版を保存\n",
    "df_filtered = df[df['year'] != 1800]\n",
    "output_filename_filtered = 'ndl_sru_for_rawgraphs_exclude1800.csv'\n",
    "df_filtered.to_csv(output_filename_filtered, index=False, encoding='utf-8')\n",
    "print(f\"保存: {output_filename_filtered}（{len(df_filtered)}件、1800年{len(df) - len(df_filtered)}件除外）\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Colabでファイルをダウンロード\n",
    "try:\n",
    "    from google.colab import files\n",
    "    files.download(output_filename)\n",
    "    files.download(output_filename_filtered)\n",
    "    print(\"ダウンロードを開始しました\")\n",
    "except ImportError:\n",
    "    print(\"ローカル環境で実行中。ファイルはカレントディレクトリに保存されています。\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}